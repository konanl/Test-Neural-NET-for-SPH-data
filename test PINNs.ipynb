{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09984b9-38c0-4b4a-822a-eaf8a88cfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from d2l import torch as d2l\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f401f1-41c7-46d7-b695-04c86724a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb7145f-fa71-4c26-ae1a-d59b32941456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file name of path\n",
    "def get_fname(path):\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a0e65c-8c37-4315-82cb-7e8d01910c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpath(path, fname):\n",
    "    return os.path.join(path, fname)\n",
    "\n",
    "def get_hdf5_group(hdf5File):\n",
    "    group = []\n",
    "    for key in hdf5File:\n",
    "        group.append(key)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e373ab5a-9c8e-4f5b-aa28-7d75a97c3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, masses, density, smoothingLength, coordinates, Velocities(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c6f9f5-633e-4221-9d8c-07899274c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = nn.Tanh\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87013219-b107-43b8-af98-68f8afb4bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X, u, layers, lb, ub):\n",
    "        \n",
    "        # boundary conditions\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        \n",
    "        # data\n",
    "        self.x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        \n",
    "        # settings\n",
    "        self.lambda_1 = torch.tensor([0.0], requires_grad=True).to(device)\n",
    "        self.lambda_2 = torch.tensor([-6.0], requires_grad=True).to(device)\n",
    "        \n",
    "        self.lambda_1 = torch.nn.Parameter(self.lambda_1)\n",
    "        self.lambda_2 = torch.nn.Parameter(self.lambda_2)\n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.dnn.register_parameter('lambda_1', self.lambda_1)\n",
    "        self.dnn.register_parameter('lambda_2', self.lambda_2)\n",
    "        \n",
    "         # optimizers: using the same settings\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), \n",
    "            lr=1.0, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-5, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"       # can be \"strong_wolfe\"\n",
    "        )\n",
    "        \n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "        self.iter = 0\n",
    "        \n",
    "    def net_u(self, x, t):  \n",
    "        u = self.dnn(torch.cat([x, t], dim=1))\n",
    "        return u\n",
    "    \n",
    "    def net_f(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        lambda_1 = self.lambda_1        \n",
    "        lambda_2 = torch.exp(self.lambda_2)\n",
    "        u = self.net_u(x, t)\n",
    "        \n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        f = u_t + lambda_1 * u * u_x - lambda_2 * u_xx\n",
    "        return f\n",
    "    \n",
    "    def loss_func(self):\n",
    "        u_pred = self.net_u(self.x, self.t)\n",
    "        f_pred = self.net_f(self.x, self.t)\n",
    "        loss = torch.mean((self.u - u_pred) ** 2) + torch.mean(f_pred ** 2)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        self.iter += 1\n",
    "        if self.iter % 100 == 0:\n",
    "            print(\n",
    "                'Loss: %e, l1: %.5f, l2: %.5f' % \n",
    "                (\n",
    "                    loss.item(), \n",
    "                    self.lambda_1.item(), \n",
    "                    torch.exp(self.lambda_2.detach()).item()\n",
    "                )\n",
    "            )\n",
    "        return loss\n",
    "    \n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()\n",
    "        for epoch in range(nIter):\n",
    "            u_pred = self.net_u(self.x, self.t)\n",
    "            f_pred = self.net_f(self.x, self.t)\n",
    "            loss = torch.mean((self.u - u_pred) ** 2) + torch.mean(f_pred ** 2)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            \n",
    "            if epoch % 10000 == 0:\n",
    "                print(\n",
    "                    'It: %d, Loss: %.3e, Lambda_1: %.3f, Lambda_2: %.6f' % \n",
    "                    (\n",
    "                        epoch, \n",
    "                        loss.item(), \n",
    "                        self.lambda_1.item(), \n",
    "                        torch.exp(self.lambda_2).item()\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "        # Backward and optimize\n",
    "        self.optimizer.step(self.loss_func)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u = self.net_u(x, t)\n",
    "        f = self.net_f(x, t)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        f = f.detach().cpu().numpy()\n",
    "        return u, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780a9e9d-c8b8-455c-a904-8e8d599ac21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01/np.pi\n",
    "\n",
    "N_u = 500\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "dataset = h5py.File(\"../../datasets_PINNs/dataset_afterDeal/train/particleID1000.hdf5\")\n",
    "x = dataset[\"dataset\"][:, 4].flatten()[:,None]\n",
    "t = np.linspace(0, len(x), len(x)).flatten()[:,None]\n",
    "Exact = dataset[\"dataset\"][:, 5].T\n",
    "\n",
    "X_star = np.concatenate([x,t], axis=1)\n",
    "u_star = Exact.flatten()[:,None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308659de-8d4b-4abc-9f99-255c60254b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 5.827e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 10000, Loss: 5.815e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 20000, Loss: 5.805e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 30000, Loss: 5.795e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 40000, Loss: 5.786e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 50000, Loss: 5.778e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 60000, Loss: 5.771e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 70000, Loss: 5.765e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 80000, Loss: 5.759e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 90000, Loss: 5.755e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 100000, Loss: 5.751e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 110000, Loss: 5.749e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 120000, Loss: 5.747e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 130000, Loss: 5.746e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 140000, Loss: 5.745e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 150000, Loss: 5.745e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 160000, Loss: 5.745e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 170000, Loss: 5.745e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n",
      "It: 180000, Loss: 5.745e+08, Lambda_1: 0.000, Lambda_2: 0.002479\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "noise = 0.0            \n",
    "\n",
    "# create training set\n",
    "idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
    "X_u_train = X_star[idx,:]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "# training\n",
    "model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n",
    "model.train(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc61c36-0599-421f-825a-793a595647fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd813a6a-1b5f-43d4-9920-8d8a76d1f5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5c411-c0ea-4d54-94a8-d02bb08e6db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7090e1-2965-46c2-be04-78b1f6019490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d374427-fcfd-40fe-a2fa-aa59e20fa316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
